{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/j9Kdi6wBcORuWKHP3+Sf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARASEON/Deep_Learning_tensorflow/blob/main/Day3_transfer_learning_German_Traffic_signs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**German Traffic signs**\n",
        "* class: 43\n",
        "* data length: 50,000\n",
        "* size ranging: 15 '* 15 to 250 '* 250 pixels.\n",
        "* val_loss < 0.5"
      ],
      "metadata": {
        "id": "lztEV-ztDqHR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ruebAfqw1tyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9772b898-cb60-4b22-d9cf-414ff0095ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31367 files belonging to 43 classes.\n",
            "Found 7842 files belonging to 43 classes.\n",
            "Epoch 1/50\n",
            "981/981 [==============================] - ETA: 0s - loss: 1.7774 - acc: 0.4880\n",
            "Epoch 1: val_loss improved from inf to 0.57007, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 22s 11ms/step - loss: 1.7774 - acc: 0.4880 - val_loss: 0.5701 - val_acc: 0.8318\n",
            "Epoch 2/50\n",
            "974/981 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8541\n",
            "Epoch 2: val_loss improved from 0.57007 to 0.20689, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.4725 - acc: 0.8543 - val_loss: 0.2069 - val_acc: 0.9417\n",
            "Epoch 3/50\n",
            "977/981 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9221\n",
            "Epoch 3: val_loss improved from 0.20689 to 0.14879, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.2576 - acc: 0.9221 - val_loss: 0.1488 - val_acc: 0.9607\n",
            "Epoch 4/50\n",
            "971/981 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9461\n",
            "Epoch 4: val_loss improved from 0.14879 to 0.09082, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.1733 - acc: 0.9464 - val_loss: 0.0908 - val_acc: 0.9754\n",
            "Epoch 5/50\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9585\n",
            "Epoch 5: val_loss improved from 0.09082 to 0.07866, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.1341 - acc: 0.9584 - val_loss: 0.0787 - val_acc: 0.9776\n",
            "Epoch 6/50\n",
            "979/981 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9647\n",
            "Epoch 6: val_loss improved from 0.07866 to 0.06369, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.1149 - acc: 0.9647 - val_loss: 0.0637 - val_acc: 0.9813\n",
            "Epoch 7/50\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.0959 - acc: 0.9699\n",
            "Epoch 7: val_loss improved from 0.06369 to 0.05939, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0959 - acc: 0.9699 - val_loss: 0.0594 - val_acc: 0.9834\n",
            "Epoch 8/50\n",
            "975/981 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9742\n",
            "Epoch 8: val_loss improved from 0.05939 to 0.05161, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0822 - acc: 0.9742 - val_loss: 0.0516 - val_acc: 0.9860\n",
            "Epoch 9/50\n",
            "976/981 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9771\n",
            "Epoch 9: val_loss did not improve from 0.05161\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0709 - acc: 0.9771 - val_loss: 0.0574 - val_acc: 0.9839\n",
            "Epoch 10/50\n",
            "970/981 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9785\n",
            "Epoch 10: val_loss improved from 0.05161 to 0.04741, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0677 - acc: 0.9785 - val_loss: 0.0474 - val_acc: 0.9856\n",
            "Epoch 11/50\n",
            "972/981 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9807\n",
            "Epoch 11: val_loss improved from 0.04741 to 0.04413, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0617 - acc: 0.9807 - val_loss: 0.0441 - val_acc: 0.9874\n",
            "Epoch 12/50\n",
            "976/981 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9826\n",
            "Epoch 12: val_loss improved from 0.04413 to 0.04383, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 10s 11ms/step - loss: 0.0566 - acc: 0.9827 - val_loss: 0.0438 - val_acc: 0.9879\n",
            "Epoch 13/50\n",
            "979/981 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9844\n",
            "Epoch 13: val_loss did not improve from 0.04383\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0503 - acc: 0.9844 - val_loss: 0.0466 - val_acc: 0.9870\n",
            "Epoch 14/50\n",
            "978/981 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9839\n",
            "Epoch 14: val_loss did not improve from 0.04383\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0474 - acc: 0.9839 - val_loss: 0.0440 - val_acc: 0.9887\n",
            "Epoch 15/50\n",
            "971/981 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9843\n",
            "Epoch 15: val_loss did not improve from 0.04383\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0498 - acc: 0.9843 - val_loss: 0.0488 - val_acc: 0.9857\n",
            "Epoch 16/50\n",
            "974/981 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9878\n",
            "Epoch 16: val_loss improved from 0.04383 to 0.03443, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0391 - acc: 0.9878 - val_loss: 0.0344 - val_acc: 0.9890\n",
            "Epoch 17/50\n",
            "970/981 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9857\n",
            "Epoch 17: val_loss did not improve from 0.03443\n",
            "981/981 [==============================] - 9s 10ms/step - loss: 0.0451 - acc: 0.9857 - val_loss: 0.0351 - val_acc: 0.9916\n",
            "Epoch 18/50\n",
            "977/981 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9889\n",
            "Epoch 18: val_loss did not improve from 0.03443\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0368 - acc: 0.9888 - val_loss: 0.0366 - val_acc: 0.9911\n",
            "Epoch 19/50\n",
            "976/981 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9876\n",
            "Epoch 19: val_loss did not improve from 0.03443\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0402 - acc: 0.9876 - val_loss: 0.0382 - val_acc: 0.9908\n",
            "Epoch 20/50\n",
            "975/981 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9874\n",
            "Epoch 20: val_loss improved from 0.03443 to 0.03015, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0390 - acc: 0.9874 - val_loss: 0.0301 - val_acc: 0.9912\n",
            "Epoch 21/50\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.0353 - acc: 0.9890\n",
            "Epoch 21: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 9s 10ms/step - loss: 0.0353 - acc: 0.9890 - val_loss: 0.0433 - val_acc: 0.9897\n",
            "Epoch 22/50\n",
            "975/981 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9882\n",
            "Epoch 22: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0390 - acc: 0.9882 - val_loss: 0.0514 - val_acc: 0.9902\n",
            "Epoch 23/50\n",
            "971/981 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9905\n",
            "Epoch 23: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0300 - acc: 0.9905 - val_loss: 0.0372 - val_acc: 0.9917\n",
            "Epoch 24/50\n",
            "972/981 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9897\n",
            "Epoch 24: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0335 - acc: 0.9897 - val_loss: 0.0475 - val_acc: 0.9901\n",
            "Epoch 25/50\n",
            "977/981 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9905\n",
            "Epoch 25: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0317 - acc: 0.9905 - val_loss: 0.0354 - val_acc: 0.9932\n",
            "Epoch 26/50\n",
            "976/981 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9897\n",
            "Epoch 26: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0344 - acc: 0.9897 - val_loss: 0.0369 - val_acc: 0.9912\n",
            "Epoch 27/50\n",
            "976/981 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9904\n",
            "Epoch 27: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0290 - acc: 0.9904 - val_loss: 0.0520 - val_acc: 0.9887\n",
            "Epoch 28/50\n",
            "971/981 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9904\n",
            "Epoch 28: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 9s 9ms/step - loss: 0.0319 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9913\n",
            "Epoch 29/50\n",
            "972/981 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9904\n",
            "Epoch 29: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 10s 10ms/step - loss: 0.0287 - acc: 0.9904 - val_loss: 0.0351 - val_acc: 0.9915\n",
            "Epoch 30/50\n",
            "972/981 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9906\n",
            "Epoch 30: val_loss did not improve from 0.03015\n",
            "981/981 [==============================] - 11s 11ms/step - loss: 0.0315 - acc: 0.9907 - val_loss: 0.0377 - val_acc: 0.9922\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.framework.ops import cpp_shape_inference_pb2\n",
        "import urllib\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def download_and_extract_data():\n",
        "    url = \"https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip\"\n",
        "    urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
        "\n",
        "    with zipfile.ZipFile('germantrafficsigns.zip','r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "def preprocess(image, label):\n",
        "  image /= 255\n",
        "  return image, label\n",
        "\n",
        "\n",
        "def solution_model():\n",
        "  # Downloads and extracts the dataset to the directory that\n",
        "  # contains this file.\n",
        "    download_and_extract_data()\n",
        "    BATCH_SIZE = 32\n",
        "    IMG_SIZE = 30\n",
        "  # The following code reads the training and validation data from their\n",
        "  # respective directories, resizes them into the specified image size\n",
        "  # and splits them into batches. You must fill in the image_size\n",
        "  # argument for both training and validation data.\n",
        "  # HINT: Image size is a tuple\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdirectory='train/',\n",
        "\tlabel_mode='categorical',\n",
        "\timage_size=(IMG_SIZE, IMG_SIZE),\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "    \n",
        "    val_ds = tf.keras.preprocessing.image_dataset_from_directory (\n",
        " \tdirectory='validation/',\n",
        "\tlabel_mode='categorical',\n",
        "\timage_size=(IMG_SIZE, IMG_SIZE),\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "    \n",
        "  # Normalizes train and validation datasets using the\n",
        "  # preprocess() function.\n",
        "  # Also makes other calls, as evident from the code, to prepare them for\n",
        "  # training.\n",
        "  # Do not batch or resize the images in the dataset here since itâ€™s already\n",
        "  # been done previously.\n",
        "    train_ds = train_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "        tf.data.experimental.AUTOTUNE)\n",
        "    val_ds = val_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  # Code to define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dropout(0.25),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(43, activation='softmax')\n",
        "    ])\n",
        "  # Code to compile and train the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['acc']\n",
        "    )\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    checkpoint_path = 'tmp_checkpoint.ckpt'\n",
        "    checkpoint = ModelCheckpoint(checkpoint_path,\n",
        "                 save_weights_only=True,\n",
        "                 save_best_only=True,\n",
        "                 monitor='val_loss',\n",
        "                 verbose=1)\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=50,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "    model.load_weights(checkpoint_path)\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  model = solution_model()\n",
        "  model.save('german_traffic_sign-cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT\n",
        "* transfer_learning\n",
        "* prompt:please code with \"German Traffic signs\" dataset from tensorflow_datasets. use the transfer learning to get under 0.5 val_loss.\n",
        "* responds: Here, we've used the ImageDataGenerator class from Keras to perform real-time data augmentation on the images during training. We've also used the MobileNetV2 model from Keras applications as the base model and added some layers on top of it to make the final model. Finally, we've set the trainable property of the base model to False, so that only the added layers are trained during fine-tuning. With these changes, we should be able to get a validation loss under 0.5.\n"
      ],
      "metadata": {
        "id": "xFq2jj59DqOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def download_and_extract_data():\n",
        "    url = \"https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip\"\n",
        "    urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
        "\n",
        "    with zipfile.ZipFile('germantrafficsigns.zip','r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "def preprocess(image, label):\n",
        "  image /= 255\n",
        "  return image, label\n",
        "\n",
        "def solution_model():\n",
        "    # Downloads and extracts the dataset to the directory that\n",
        "    # contains this file.\n",
        "    download_and_extract_data()\n",
        "    BATCH_SIZE = 32\n",
        "    IMG_SIZE = 224\n",
        "\n",
        "    # The following code reads the training and validation data from their\n",
        "    # respective directories, resizes them into the specified image size\n",
        "    # and splits them into batches.\n",
        "    train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
        "    train_ds = train_datagen.flow_from_directory(\n",
        "        directory='train/',\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
        "    val_ds = val_datagen.flow_from_directory(\n",
        "        directory='validation/',\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # Code to define the model\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                                                   include_top=False,\n",
        "                                                   weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(43, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Code to compile and train the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['acc']\n",
        "    )\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    checkpoint_path = 'tmp_checkpoint.ckpt'\n",
        "    checkpoint = ModelCheckpoint(checkpoint_path,\n",
        "                 save_weights_only=True,\n",
        "                 save_best_only=True,\n",
        "                 monitor='val_loss',\n",
        "                 verbose=1)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs = 100,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_path)\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  model = solution_model()\n",
        "  model.save(\"german_traffic_sign_tr.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5-BqDOfo18A",
        "outputId": "7439e206-7100-48db-e5eb-d90c52d50c80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31367 images belonging to 43 classes.\n",
            "Found 7842 images belonging to 43 classes.\n",
            "Epoch 1/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 2.3477 - acc: 0.3831\n",
            "Epoch 1: val_loss improved from inf to 1.54909, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 68s 66ms/step - loss: 2.3477 - acc: 0.3830 - val_loss: 1.5491 - val_acc: 0.5199\n",
            "Epoch 2/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 1.3259 - acc: 0.5672\n",
            "Epoch 2: val_loss improved from 1.54909 to 1.19036, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 62s 63ms/step - loss: 1.3257 - acc: 0.5673 - val_loss: 1.1904 - val_acc: 0.6019\n",
            "Epoch 3/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.9877 - acc: 0.6628\n",
            "Epoch 3: val_loss improved from 1.19036 to 0.90530, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 70s 71ms/step - loss: 0.9875 - acc: 0.6628 - val_loss: 0.9053 - val_acc: 0.6912\n",
            "Epoch 4/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.8442 - acc: 0.7084\n",
            "Epoch 4: val_loss improved from 0.90530 to 0.78966, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.8440 - acc: 0.7085 - val_loss: 0.7897 - val_acc: 0.7313\n",
            "Epoch 5/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.7334 - acc: 0.7479\n",
            "Epoch 5: val_loss improved from 0.78966 to 0.76922, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.7334 - acc: 0.7479 - val_loss: 0.7692 - val_acc: 0.7529\n",
            "Epoch 6/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.6622 - acc: 0.7679\n",
            "Epoch 6: val_loss improved from 0.76922 to 0.72226, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 62s 63ms/step - loss: 0.6622 - acc: 0.7679 - val_loss: 0.7223 - val_acc: 0.7641\n",
            "Epoch 7/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.6179 - acc: 0.7904\n",
            "Epoch 7: val_loss improved from 0.72226 to 0.66550, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 62s 63ms/step - loss: 0.6179 - acc: 0.7904 - val_loss: 0.6655 - val_acc: 0.7796\n",
            "Epoch 8/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.5790 - acc: 0.8016\n",
            "Epoch 8: val_loss did not improve from 0.66550\n",
            "981/981 [==============================] - 70s 71ms/step - loss: 0.5790 - acc: 0.8016 - val_loss: 0.7074 - val_acc: 0.7816\n",
            "Epoch 9/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.5377 - acc: 0.8191\n",
            "Epoch 9: val_loss improved from 0.66550 to 0.65093, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 62s 63ms/step - loss: 0.5377 - acc: 0.8191 - val_loss: 0.6509 - val_acc: 0.7972\n",
            "Epoch 10/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.5249 - acc: 0.8238\n",
            "Epoch 10: val_loss improved from 0.65093 to 0.63779, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.5249 - acc: 0.8238 - val_loss: 0.6378 - val_acc: 0.8037\n",
            "Epoch 11/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.4917 - acc: 0.8316\n",
            "Epoch 11: val_loss improved from 0.63779 to 0.63361, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.4917 - acc: 0.8316 - val_loss: 0.6336 - val_acc: 0.8088\n",
            "Epoch 12/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.4692 - acc: 0.8438\n",
            "Epoch 12: val_loss improved from 0.63361 to 0.62815, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.4692 - acc: 0.8438 - val_loss: 0.6281 - val_acc: 0.8115\n",
            "Epoch 13/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.4513 - acc: 0.8480\n",
            "Epoch 13: val_loss improved from 0.62815 to 0.60470, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.4513 - acc: 0.8480 - val_loss: 0.6047 - val_acc: 0.8166\n",
            "Epoch 14/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.4487 - acc: 0.8539\n",
            "Epoch 14: val_loss did not improve from 0.60470\n",
            "981/981 [==============================] - 59s 60ms/step - loss: 0.4487 - acc: 0.8539 - val_loss: 0.6113 - val_acc: 0.8224\n",
            "Epoch 15/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.4179 - acc: 0.8613\n",
            "Epoch 15: val_loss did not improve from 0.60470\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.4178 - acc: 0.8613 - val_loss: 0.6345 - val_acc: 0.8166\n",
            "Epoch 16/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.4164 - acc: 0.8638\n",
            "Epoch 16: val_loss improved from 0.60470 to 0.59734, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.4162 - acc: 0.8638 - val_loss: 0.5973 - val_acc: 0.8224\n",
            "Epoch 17/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.4063 - acc: 0.8665\n",
            "Epoch 17: val_loss did not improve from 0.59734\n",
            "981/981 [==============================] - 59s 60ms/step - loss: 0.4063 - acc: 0.8665 - val_loss: 0.6192 - val_acc: 0.8141\n",
            "Epoch 18/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3993 - acc: 0.8709\n",
            "Epoch 18: val_loss improved from 0.59734 to 0.57214, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 61s 62ms/step - loss: 0.3993 - acc: 0.8709 - val_loss: 0.5721 - val_acc: 0.8421\n",
            "Epoch 19/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8738\n",
            "Epoch 19: val_loss improved from 0.57214 to 0.52544, saving model to tmp_checkpoint.ckpt\n",
            "981/981 [==============================] - 60s 62ms/step - loss: 0.3804 - acc: 0.8737 - val_loss: 0.5254 - val_acc: 0.8449\n",
            "Epoch 20/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3788 - acc: 0.8764\n",
            "Epoch 20: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 59s 60ms/step - loss: 0.3788 - acc: 0.8764 - val_loss: 0.6046 - val_acc: 0.8304\n",
            "Epoch 21/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3706 - acc: 0.8788\n",
            "Epoch 21: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 58s 59ms/step - loss: 0.3706 - acc: 0.8788 - val_loss: 0.5863 - val_acc: 0.8340\n",
            "Epoch 22/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3668 - acc: 0.8823\n",
            "Epoch 22: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 59s 61ms/step - loss: 0.3668 - acc: 0.8823 - val_loss: 0.5843 - val_acc: 0.8415\n",
            "Epoch 23/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3561 - acc: 0.8849\n",
            "Epoch 23: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.3561 - acc: 0.8849 - val_loss: 0.5676 - val_acc: 0.8321\n",
            "Epoch 24/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3540 - acc: 0.8857\n",
            "Epoch 24: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 59s 60ms/step - loss: 0.3540 - acc: 0.8857 - val_loss: 0.7584 - val_acc: 0.8062\n",
            "Epoch 25/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.3446 - acc: 0.8895\n",
            "Epoch 25: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.3447 - acc: 0.8894 - val_loss: 0.6545 - val_acc: 0.8279\n",
            "Epoch 26/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3561 - acc: 0.8873\n",
            "Epoch 26: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.3561 - acc: 0.8873 - val_loss: 0.5891 - val_acc: 0.8378\n",
            "Epoch 27/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8964\n",
            "Epoch 27: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.3253 - acc: 0.8963 - val_loss: 0.5937 - val_acc: 0.8386\n",
            "Epoch 28/100\n",
            "981/981 [==============================] - ETA: 0s - loss: 0.3322 - acc: 0.8941\n",
            "Epoch 28: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 59s 61ms/step - loss: 0.3322 - acc: 0.8941 - val_loss: 0.5895 - val_acc: 0.8398\n",
            "Epoch 29/100\n",
            "980/981 [============================>.] - ETA: 0s - loss: 0.3185 - acc: 0.8983\n",
            "Epoch 29: val_loss did not improve from 0.52544\n",
            "981/981 [==============================] - 60s 61ms/step - loss: 0.3187 - acc: 0.8982 - val_loss: 0.6403 - val_acc: 0.8284\n"
          ]
        }
      ]
    }
  ]
}