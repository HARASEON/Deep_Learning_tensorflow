{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKv9rMLINuBObIkEhZcxVN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARASEON/Deep_Learning_tensorflow/blob/main/Day3_Data_augmentation_horses_vs_humans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "GAN(Generative Adversarial Networks) by Goodfellow\n",
        "* 생성하는 딥러닝 모델\n",
        "* 데이터로 표현할 수 있는 모든 것을 생성할 수 있음\n",
        "* 실제와 유사한 형태로 생성\n",
        "* 없는 데이터를 채울 때\n",
        "* Super-Resolution: 저화질을 고화질로\n",
        "* Image-to-Image translation\n",
        "\n",
        "DCGAN(Generative Adversarial Networks)-Generator, Descriminator\n",
        "\n",
        "* Goal: val_loss < 0.6"
      ],
      "metadata": {
        "id": "LTMwmXFsS7e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRt5JcqWVM3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b293ee03-2a04-40db-9937-dd127a04bec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.4995\n",
            "Epoch 1: val_loss improved from inf to 0.69208, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 40s 805ms/step - loss: 0.6961 - accuracy: 0.4995 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.5394\n",
            "Epoch 2: val_loss improved from 0.69208 to 0.66939, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 26s 794ms/step - loss: 0.6911 - accuracy: 0.5394 - val_loss: 0.6694 - val_accuracy: 0.6367\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.6310\n",
            "Epoch 3: val_loss did not improve from 0.66939\n",
            "33/33 [==============================] - 26s 789ms/step - loss: 0.6418 - accuracy: 0.6310 - val_loss: 0.7461 - val_accuracy: 0.5469\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7011\n",
            "Epoch 4: val_loss did not improve from 0.66939\n",
            "33/33 [==============================] - 26s 784ms/step - loss: 0.5653 - accuracy: 0.7011 - val_loss: 1.1740 - val_accuracy: 0.7070\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7585\n",
            "Epoch 5: val_loss did not improve from 0.66939\n",
            "33/33 [==============================] - 26s 789ms/step - loss: 0.5072 - accuracy: 0.7585 - val_loss: 1.2719 - val_accuracy: 0.7148\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.7887\n",
            "Epoch 6: val_loss did not improve from 0.66939\n",
            "33/33 [==============================] - 26s 788ms/step - loss: 0.4537 - accuracy: 0.7887 - val_loss: 0.8412 - val_accuracy: 0.7227\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.8179\n",
            "Epoch 7: val_loss improved from 0.66939 to 0.65070, saving model to my_checkpoint.ckpt\n",
            "33/33 [==============================] - 26s 786ms/step - loss: 0.4226 - accuracy: 0.8179 - val_loss: 0.6507 - val_accuracy: 0.7500\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4200 - accuracy: 0.7994\n",
            "Epoch 8: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 787ms/step - loss: 0.4200 - accuracy: 0.7994 - val_loss: 1.4702 - val_accuracy: 0.6445\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.8617\n",
            "Epoch 9: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 27s 793ms/step - loss: 0.3410 - accuracy: 0.8617 - val_loss: 1.0158 - val_accuracy: 0.7891\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.8393\n",
            "Epoch 10: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 797ms/step - loss: 0.3621 - accuracy: 0.8393 - val_loss: 0.9948 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.8890\n",
            "Epoch 11: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 785ms/step - loss: 0.2830 - accuracy: 0.8890 - val_loss: 1.0493 - val_accuracy: 0.7773\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.8870\n",
            "Epoch 12: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 792ms/step - loss: 0.2824 - accuracy: 0.8870 - val_loss: 0.9975 - val_accuracy: 0.7734\n",
            "Epoch 13/50\n",
            "32/33 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9219\n",
            "Epoch 13: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 782ms/step - loss: 0.2110 - accuracy: 0.9221 - val_loss: 1.0293 - val_accuracy: 0.8086\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2446 - accuracy: 0.9056\n",
            "Epoch 14: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 788ms/step - loss: 0.2446 - accuracy: 0.9056 - val_loss: 1.6826 - val_accuracy: 0.6914\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9202\n",
            "Epoch 15: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 27s 820ms/step - loss: 0.2136 - accuracy: 0.9202 - val_loss: 1.0467 - val_accuracy: 0.7812\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9250\n",
            "Epoch 16: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 781ms/step - loss: 0.2008 - accuracy: 0.9250 - val_loss: 1.5471 - val_accuracy: 0.7266\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9387\n",
            "Epoch 17: val_loss did not improve from 0.65070\n",
            "33/33 [==============================] - 26s 787ms/step - loss: 0.1604 - accuracy: 0.9387 - val_loss: 1.3253 - val_accuracy: 0.7617\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import urllib\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D,Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Data loading\n",
        "_TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "_TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\n",
        "local_zip = 'horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/horse-or-human/')\n",
        "zip_ref.close()\n",
        "urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\n",
        "local_zip = 'validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/validation-horse-or-human/')\n",
        "zip_ref.close()\n",
        "\n",
        "# Data Generation\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1 / 255,\n",
        "        rotation_range=40,        # degree range for random rotations\n",
        "        width_shift_range=0.2,    # fraction of total width\n",
        "        height_shift_range=0.2,   # fraction of total height\n",
        "        shear_range=0.2,          # shear angle in counter-clockwise direction\n",
        "        zoom_range=0.2,           # zoom \n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255) \n",
        "\n",
        "TRAINING_DIR =  'tmp/horse-or-human/'\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAINING_DIR, \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary' # catagorical for more than 2\n",
        "       )\n",
        "\n",
        "VALIDATION_DIR = 'tmp/validation-horse-or-human/'\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        VALIDATION_DIR, \n",
        "        target_size=(300, 300), \n",
        "        class_mode='binary',\n",
        "        )\n",
        "\n",
        "# Model building\n",
        "model = tf.keras.models.Sequential([\n",
        "        Conv2D(16, (3, 3), input_shape=(300, 300, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.5),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(), \n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "# Model fitting\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_path = 'my_checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, \n",
        "                             save_best_only=True, \n",
        "                             save_weights_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit( train_generator, \n",
        "        validation_data=(validation_generator),\n",
        "        epochs=50,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "model.load_weights(checkpoint_path) \n",
        "model.save(\"horse-human(gen).h5\")"
      ]
    }
  ]
}